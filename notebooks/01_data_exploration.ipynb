{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PKM-RE: Eksplorasi Data H3N2 Hemagglutinin\n",
    "\n",
    "## Informasi Sumber Data\n",
    "\n",
    "| Atribut | Detail |\n",
    "|---------|--------|\n",
    "| **Database** | NCBI Protein Database |\n",
    "| **URL** | https://www.ncbi.nlm.nih.gov/protein |\n",
    "| **Query** | Influenza A virus H3N2 hemagglutinin human |\n",
    "| **Tanggal Download** | 18 Januari 2026 |\n",
    "| **Jumlah Sekuens** | 1500 |\n",
    "| **Format** | FASTA (Protein) |\n",
    "| **Panjang Sekuens** | 500-600 asam amino |\n",
    "\n",
    "### Referensi Database\n",
    "- NCBI Influenza Virus Resource: https://www.ncbi.nlm.nih.gov/genomes/FLU/\n",
    "- Entrez Programming Utilities: https://www.ncbi.nlm.nih.gov/books/NBK25501/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO, Entrez\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print('Libraries loaded successfully!')\n",
    "print(f'Analysis date: {datetime.now().strftime(\"%Y-%m-%d %H:%M\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dan Parse Data FASTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FASTA file\n",
    "fasta_file = '../data/raw/h3n2_ha_sequences.fasta'\n",
    "\n",
    "records = []\n",
    "for record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "    records.append({\n",
    "        'accession': record.id,\n",
    "        'description': record.description,\n",
    "        'sequence': str(record.seq),\n",
    "        'length': len(record.seq)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(f'Total sequences loaded: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ekstrak Metadata dari Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(desc):\n",
    "    \"\"\"Extract year from description\"\"\"\n",
    "    # Pattern: A/Location/Number/YEAR\n",
    "    match = re.search(r'/([12][09]\\d{2})\\)', desc)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    # Fallback: any 4-digit year\n",
    "    match = re.search(r'(20[0-2]\\d|19\\d{2})', desc)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_location(desc):\n",
    "    \"\"\"Extract location from strain name\"\"\"\n",
    "    match = re.search(r'A/([^/]+)/', desc)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return 'Unknown'\n",
    "\n",
    "def extract_strain(desc):\n",
    "    \"\"\"Extract full strain name\"\"\"\n",
    "    match = re.search(r'\\[(Influenza A virus \\([^\\]]+\\))\\]', desc)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return desc\n",
    "\n",
    "# Apply extraction\n",
    "df['year'] = df['description'].apply(extract_year)\n",
    "df['location'] = df['description'].apply(extract_location)\n",
    "df['strain'] = df['description'].apply(extract_strain)\n",
    "\n",
    "# Create NCBI link for each sequence\n",
    "df['ncbi_link'] = df['accession'].apply(lambda x: f'https://www.ncbi.nlm.nih.gov/protein/{x}')\n",
    "\n",
    "print(f'Years range: {df[\"year\"].min()} - {df[\"year\"].max()}')\n",
    "print(f'Sequences with year info: {df[\"year\"].notna().sum()}')\n",
    "df[['accession', 'year', 'location', 'length', 'ncbi_link']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter dan Sort by Year (Latest First)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sequences with valid year\n",
    "df_valid = df[df['year'].notna()].copy()\n",
    "df_valid['year'] = df_valid['year'].astype(int)\n",
    "\n",
    "# Sort by year descending (latest first)\n",
    "df_valid = df_valid.sort_values('year', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f'Sequences with valid year: {len(df_valid)}')\n",
    "print(f'\\nYear distribution:')\n",
    "print(df_valid['year'].value_counts().sort_index(ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize year distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "year_counts = df_valid['year'].value_counts().sort_index()\n",
    "year_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of Sequences')\n",
    "ax.set_title('H3N2 HA Sequences by Collection Year')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/year_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sequence Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df_valid['length'], bins=30, color='coral', edgecolor='black')\n",
    "axes[0].set_xlabel('Sequence Length (amino acids)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of HA Sequence Lengths')\n",
    "axes[0].axvline(df_valid['length'].median(), color='red', linestyle='--', label=f'Median: {df_valid[\"length\"].median()}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Boxplot by year (recent years)\n",
    "recent = df_valid[df_valid['year'] >= 2018]\n",
    "recent.boxplot(column='length', by='year', ax=axes[1])\n",
    "axes[1].set_xlabel('Year')\n",
    "axes[1].set_ylabel('Sequence Length')\n",
    "axes[1].set_title('Sequence Length by Year (2018+)')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/length_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'Length statistics:')\n",
    "print(df_valid['length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Geographic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top locations\n",
    "top_locations = df_valid['location'].value_counts().head(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "top_locations.plot(kind='barh', ax=ax, color='teal')\n",
    "ax.set_xlabel('Number of Sequences')\n",
    "ax.set_ylabel('Location')\n",
    "ax.set_title('Top 20 Locations for H3N2 HA Sequences')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/location_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quality Control & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter criteria for ML\n",
    "MIN_LENGTH = 550\n",
    "MAX_LENGTH = 580\n",
    "MIN_YEAR = 2015\n",
    "\n",
    "df_filtered = df_valid[\n",
    "    (df_valid['length'] >= MIN_LENGTH) &\n",
    "    (df_valid['length'] <= MAX_LENGTH) &\n",
    "    (df_valid['year'] >= MIN_YEAR)\n",
    "].copy()\n",
    "\n",
    "# Remove sequences with ambiguous amino acids\n",
    "df_filtered = df_filtered[~df_filtered['sequence'].str.contains('[XBZ]', regex=True)]\n",
    "\n",
    "print(f'After filtering:')\n",
    "print(f'  - Original: {len(df_valid)}')\n",
    "print(f'  - Filtered: {len(df_filtered)}')\n",
    "print(f'  - Year range: {df_filtered[\"year\"].min()} - {df_filtered[\"year\"].max()}')\n",
    "print(f'  - Length range: {df_filtered[\"length\"].min()} - {df_filtered[\"length\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV with full metadata\n",
    "output_csv = '../data/processed/h3n2_ha_processed.csv'\n",
    "df_filtered.to_csv(output_csv, index=False)\n",
    "print(f'Saved {len(df_filtered)} sequences to {output_csv}')\n",
    "\n",
    "# Save metadata summary\n",
    "metadata = {\n",
    "    'source_database': 'NCBI Protein Database',\n",
    "    'source_url': 'https://www.ncbi.nlm.nih.gov/protein',\n",
    "    'query': 'Influenza A virus H3N2 hemagglutinin human 500:600[Sequence Length]',\n",
    "    'download_date': '2026-01-18',\n",
    "    'total_downloaded': len(df),\n",
    "    'after_filtering': len(df_filtered),\n",
    "    'year_range': f'{df_filtered[\"year\"].min()}-{df_filtered[\"year\"].max()}',\n",
    "    'length_range': f'{df_filtered[\"length\"].min()}-{df_filtered[\"length\"].max()}',\n",
    "    'filter_criteria': {\n",
    "        'min_length': MIN_LENGTH,\n",
    "        'max_length': MAX_LENGTH,\n",
    "        'min_year': MIN_YEAR,\n",
    "        'exclude_ambiguous': True\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/processed/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print('Metadata saved to metadata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Provenance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create provenance table for top 20 sequences\n",
    "provenance = df_filtered[['accession', 'strain', 'year', 'location', 'length', 'ncbi_link']].head(20)\n",
    "provenance.columns = ['Accession', 'Strain Name', 'Year', 'Location', 'Length', 'NCBI Link']\n",
    "\n",
    "print('\\n=== DATA PROVENANCE (Top 20 Latest Sequences) ===')\n",
    "print('Each sequence can be verified at the NCBI link provided\\n')\n",
    "provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save provenance to HTML for documentation\n",
    "html_table = provenance.to_html(index=False, render_links=True, escape=False)\n",
    "html_table = html_table.replace('&lt;', '<').replace('&gt;', '>')\n",
    "\n",
    "with open('../results/data_provenance.html', 'w') as f:\n",
    "    f.write(f'''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>H3N2 Data Provenance</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "        table {{ border-collapse: collapse; width: 100%; }}\n",
    "        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "        th {{ background-color: #4CAF50; color: white; }}\n",
    "        tr:nth-child(even) {{ background-color: #f2f2f2; }}\n",
    "        a {{ color: #0066cc; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>H3N2 HA Sequence Data Provenance</h1>\n",
    "    <p><strong>Source:</strong> NCBI Protein Database</p>\n",
    "    <p><strong>Download Date:</strong> 18 January 2026</p>\n",
    "    <p><strong>Total Sequences:</strong> {len(df_filtered)}</p>\n",
    "    {html_table}\n",
    "</body>\n",
    "</html>\n",
    "''')\n",
    "print('Provenance table saved to results/data_provenance.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Data telah diproses dan siap untuk tahap selanjutnya:\n",
    "1. **Feature Extraction** - Ekstraksi fitur fisikokimia\n",
    "2. **Model Training** - Training XGBoost untuk prediksi antigenic drift"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}